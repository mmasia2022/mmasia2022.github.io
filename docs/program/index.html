<!doctype html><html lang=en-us>
<head>
<meta charset=utf-8>
<meta name=robots content="all,follow">
<meta name=googlebot content="index,follow,snippet,archive">
<meta name=viewport content="width=device-width,initial-scale=1">
<title>Program</title>
<meta name=author content="DevCows">
<meta name=keywords content="announcement">
<meta name=description content="ACM Multimedia Asia 2022">
<meta name=generator content="Hugo 0.89.4">
<link href="//fonts.googleapis.com/css?family=Roboto:400,100,100italic,300,300italic,500,700,800" rel=stylesheet type=text/css>
<link rel=stylesheet href=//use.fontawesome.com/releases/v5.11.2/css/all.css>
<link rel=stylesheet href=//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css integrity=sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u crossorigin=anonymous>
<link href=/css/animate.css rel=stylesheet>
<link href=/css/style.marsala.css rel=stylesheet id=theme-stylesheet>
<link href=/css/custom.css rel=stylesheet><!--[if lt IE 9]><script src=https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js></script>
<script src=https://oss.maxcdn.com/respond/1.4.2/respond.min.js></script><![endif]-->
<link rel="shortcut icon" href=/img/favicon.ico type=image/x-icon>
<link rel=apple-touch-icon href=/img/apple-touch-icon.png>
<link href=/css/owl.carousel.css rel=stylesheet>
<link href=/css/owl.theme.css rel=stylesheet>
<link rel=alternate href=https://www.mmasia2022.org/index.xml type=application/rss+xml title="ACM Multimedia Asia 2022">
<meta name=twitter:card content="summary">
<meta name=twitter:site content="@GoHugoIO">
<meta name=twitter:title content="Program">
<meta name=twitter:description content="ACM Multimedia Asia 2022">
<link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css>
</head>
<body>
<div id=all>
<header class=navbar-affixed-top data-spy=affix data-offset-top=62>
<div class="navbar navbar-default yamm" role=navigation id=navbar>
<div class=container>
<div class=navbar-header>
<a class="navbar-brand home" href=/>
<img src=/img/logo-acmmmasia2022.png alt="Program logo" class="hidden-xs hidden-sm">
<img src=/img/logo-acmmmasia2022.png alt="Program logo" class="visible-xs visible-sm">
<span class=sr-only>Program - go to homepage</span>
</a>
<div class=navbar-buttons>
<button type=button class="navbar-toggle btn-template-main" data-toggle=collapse data-target=#navigation>
<span class=sr-only>Toggle Navigation</span>
<i class="fas fa-align-justify"></i>
</button>
</div>
</div>
<div class="navbar-collapse collapse" id=navigation>
<ul class="nav navbar-nav navbar-right">
<li class=dropdown>
<a href=/>Home</a>
</li>
<li class=dropdown>
<a href=# class=dropdown-toggle data-toggle=dropdown role=button aria-haspopup=true aria-expanded=false>Calls & Dates <span class=caret></span></a>
<ul class=dropdown-menu>
<li><a href=/important_dates/>Important Dates</a></li>
<li><a href=/call_for_workshop_proposals/>Call for Workshop Proposals</a></li>
<li><a href=/call_for_regular_papers/>Call for Regular Papers</a></li>
<li><a href=/call_for_short_papers/>Call for Short Papers</a></li>
<li><a href=/call_for_demo_papers/>Call for Demo Papers</a></li>
<li><a href=/call_for_tutorials/>Call for Tutorials</a></li>
<li><a href=/call_for_workshop_papers/>Call for Workshop Papers</a></li>
</ul>
</li>
<li class=dropdown>
<a href=# class=dropdown-toggle data-toggle=dropdown role=button aria-haspopup=true aria-expanded=false>Program <span class=caret></span></a>
<ul class=dropdown-menu>
<li><a href=/program>Program</a></li>
<li><a href=/keynote>Keynote Talks</a></li>
<li><a href=/tutorials>Tutorials</a></li>
<li><a href=/workshop>Workshop</a></li>
</ul>
</li>
<li class=dropdown>
<a href=# class=dropdown-toggle data-toggle=dropdown role=button aria-haspopup=true aria-expanded=false>Attend <span class=caret></span></a>
<ul class=dropdown-menu>
<li><a href=/registration>Registration</a></li>
<li><a href=/student-travel-grants>Student Travel Grants</a></li>
<li><a href=/venue>Venue</a></li>
</ul>
</li>
<li class=dropdown>
<a href=/sponsors/>Sponsors</a>
</li>
<li class=dropdown>
<a href=/organizers/>Organizers</a>
</li>
</ul>
</div>
<div class="collapse clearfix" id=search>
<form class=navbar-form role=search>
<div class=input-group>
<input type=text class=form-control placeholder=Search>
<span class=input-group-btn>
<button type=submit class="btn btn-template-main"><i class="fas fa-search"></i></button>
</span>
</div>
</form>
</div>
</div>
</div>
</header>
<div id=heading-breadcrumbs>
<div class=container>
<div class=row>
<div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
<h1>Program</h1>
</div>
</div>
</div>
</div>
<div id=content>
<div class=container role=main>
<div class=row>
<div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1 lead">
<h2>Program at a glance</h2>
<div id=program-at-a-glance>
<div id=program-glance-one-day>
<div id=program-glance-day>December 13</div>
<a id=program-glance href=#2022-12-13T09%3a15%3a00%2b09%3a00>
<div id=program-glance-session class=registration style=height:30px;position:absolute;top:25px>
<span id=program-glance-time>09:15
</span>
Registration
</div>
</a>
<a id=program-glance href=#2022-12-13T09%3a45%3a00%2b09%3a00>
<div id=program-glance-session class=workshop style=height:120px;position:absolute;top:55px>
<span id=program-glance-time>09:45
<span id=program-glance-end-time>
&#150;
11:45
</span>
</span>
Workshop: Multimedia Understanding with Pre-trained Models
</div>
</a>
<a id=program-glance href=#2022-12-13T13%3a00%3a00%2b09%3a00>
<div id=program-glance-session class=tutorial style=height:120px;position:absolute;top:250px>
<span id=program-glance-time>13:00
<span id=program-glance-end-time>
&#150;
15:00
</span>
</span>
Tutorial 1: Synthetic Data and Multimedia
</div>
</a>
<a id=program-glance href=#2022-12-13T15%3a00%3a00%2b09%3a00>
<div id=program-glance-session class=tutorial style=height:120px;position:absolute;top:370px>
<span id=program-glance-time>15:00
<span id=program-glance-end-time>
&#150;
17:00
</span>
</span>
Tutorial 2: Human-centric Visual Understanding
</div>
</a>
</div>
<div id=program-glance-one-day>
<div id=program-glance-day>December 14</div>
<a id=program-glance href=#2022-12-14T09%3a45%3a00%2b09%3a00>
<div id=program-glance-session class=opening style=height:15px;position:absolute;top:55px>
<span id=program-glance-time>09:45
<span id=program-glance-end-time>
&#150;
10:00
</span>
</span>
Opening
</div>
</a>
<a id=program-glance href=#2022-12-14T10%3a00%3a00%2b09%3a00>
<div id=program-glance-session class=oral style=height:100px;position:absolute;top:70px>
<span id=program-glance-time>10:00
<span id=program-glance-end-time>
&#150;
11:40
</span>
</span>
Oral 1-1 Award Session
</div>
</a>
<a id=program-glance href=#2022-12-14T13%3a00%3a00%2b09%3a00>
<div id=program-glance-session class=keynote style=height:60px;position:absolute;top:250px>
<span id=program-glance-time>13:00
<span id=program-glance-end-time>
&#150;
14:00
</span>
</span>
Keynote 1: Machine Learning for Creative Workflow
</div>
</a>
<a id=program-glance href=#2022-12-14T14%3a00%3a00%2b09%3a00>
<div id=program-glance-session class=demo style=height:30px;position:absolute;top:310px>
<span id=program-glance-time>14:00
<span id=program-glance-end-time>
&#150;
14:30
</span>
</span>
Demo Spotlight
</div>
</a>
<a id=program-glance href=#2022-12-14T14%3a30%3a00%2b09%3a00>
<div id=program-glance-session class=poster_demo style=height:75px;position:absolute;top:340px>
<span id=program-glance-time>14:30
<span id=program-glance-end-time>
&#150;
15:45
</span>
</span>
Poster+Demo
</div>
</a>
<a id=program-glance href=#2022-12-14T16%3a00%3a00%2b09%3a00>
<div id=program-glance-session class=oral style=height:60px;position:absolute;top:430px>
<span id=program-glance-time>16:00
<span id=program-glance-end-time>
&#150;
17:00
</span>
</span>
Oral 1-2 Text, Speech, and Vision
</div>
</a>
</div>
<div id=program-glance-one-day>
<div id=program-glance-day>December 15</div>
<a id=program-glance href=#2022-12-15T10%3a00%3a00%2b09%3a00>
<div id=program-glance-session class=oral style=height:90px;position:absolute;top:70px>
<span id=program-glance-time>10:00
<span id=program-glance-end-time>
&#150;
11:30
</span>
</span>
Oral 2-1 Video Compression, Broadcasting, and Analysis
</div>
</a>
<a id=program-glance href=#2022-12-15T13%3a00%3a00%2b09%3a00>
<div id=program-glance-session class=keynote style=height:60px;position:absolute;top:250px>
<span id=program-glance-time>13:00
<span id=program-glance-end-time>
&#150;
14:00
</span>
</span>
Keynote 2: Connecting the Dots: Digital Humanities and Historical Big Data Research for Japanese Culture
</div>
</a>
<a id=program-glance href=#2022-12-15T14%3a00%3a00%2b09%3a00>
<div id=program-glance-session class=short style=height:60px;position:absolute;top:310px>
<span id=program-glance-time>14:00
<span id=program-glance-end-time>
&#150;
15:00
</span>
</span>
Short Spotlight
</div>
</a>
<a id=program-glance href=#2022-12-15T15%3a15%3a00%2b09%3a00>
<div id=program-glance-session class=poster_demo style=height:105px;position:absolute;top:385px>
<span id=program-glance-time>15:15
<span id=program-glance-end-time>
&#150;
17:00
</span>
</span>
Poster+Demo
</div>
</a>
</div>
<div id=program-glance-one-day>
<div id=program-glance-day>December 16</div>
<a id=program-glance href=#2022-12-16T10%3a00%3a00%2b09%3a00>
<div id=program-glance-session class=oral style=height:90px;position:absolute;top:70px>
<span id=program-glance-time>10:00
<span id=program-glance-end-time>
&#150;
11:30
</span>
</span>
Oral 3-1 Low-level Vision and Image Processing
</div>
</a>
<a id=program-glance href=#2022-12-16T13%3a00%3a00%2b09%3a00>
<div id=program-glance-session class=oral style=height:90px;position:absolute;top:250px>
<span id=program-glance-time>13:00
<span id=program-glance-end-time>
&#150;
14:30
</span>
</span>
Oral 3-2 Robustness, Data Augmentation and Disentangling
</div>
</a>
<a id=program-glance href=#2022-12-16T14%3a30%3a00%2b09%3a00>
<div id=program-glance-session class=closing style=height:15px;position:absolute;top:340px>
<span id=program-glance-time>14:30
<span id=program-glance-end-time>
&#150;
14:45
</span>
</span>
Closing
</div>
</a>
</div>
</div>
<p><br><br></p>
<h2 id=program>Program</h2>
<div>
<div id=program-day>
<div id=program-display-date>December 13</div>
<div id=program-session>
<div id=program-time>
<a id=program name=2022-12-13T09:15:00+09:00>09:15
&#150;
</a>
</div>
<div id=program-session-name>
Registration
</div>
</div>
<div id=program-session>
<div id=program-time>
<a id=program name=2022-12-13T09:45:00+09:00>09:45
&#150;
11:45
</a>
</div>
<div id=program-session-name>
<a href=http://staff.ustc.edu.cn/~zhwg/MMAsia_2022_workshop/index.html>Workshop: Multimedia Understanding with Pre-trained Models</a>
</div>
</div>
<div id=program-session>
<div id=program-time>
<a id=program name=2022-12-13T13:00:00+09:00>13:00
&#150;
15:00
</a>
</div>
<div id=program-session-name>
<a href=/tutorials/#tutorial1>Tutorial 1: Synthetic Data and Multimedia</a>
</div>
</div>
<div id=program-session>
<div id=program-time>
<a id=program name=2022-12-13T15:00:00+09:00>15:00
&#150;
17:00
</a>
</div>
<div id=program-session-name>
<a href=/tutorials/#tutorial2>Tutorial 2: Human-centric Visual Understanding</a>
</div>
</div>
</div>
<div id=program-day>
<div id=program-display-date>December 14</div>
<div id=program-session>
<div id=program-time>
<a id=program name=2022-12-14T09:45:00+09:00>09:45
&#150;
10:00
</a>
</div>
<div id=program-session-name>
Opening
</div>
</div>
<div id=program-session>
<div id=program-time>
<a id=program name=2022-12-14T10:00:00+09:00>10:00
&#150;
11:40
</a>
</div>
<div id=program-session-name>
Oral 1-1 Award Session
</div>
</div>
<div id=program-presentatin-list>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>89</span> TFM a Dataset for Detection and Recognition of Masked Faces in the Wild</div><br>
<div id=program-paper-author>Gibran Benitez-Garcia (The University of Electro-Communications)*; Miguel Jimenez-Martinez (INSTITUTO POLITECNICO NACIONAL); Jesus Olivares-Mercado (INSTITUTO POLITECNICO NACIONAL); Hiroki Takahashi (the University of Electro-Communications)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>93</span> Deep Image and Kernel Prior Learning for Blind Super-Resolution</div><br>
<div id=program-paper-author>Kazuhiro Yamawaki (Yamaguchi University); Xian-Hua Han (Yamaguchi University)*</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>42</span> Asymmetric Label Propagation for Video Object Segmentation</div><br>
<div id=program-paper-author>Zhen Chen (Peking University); Ming Yang (Horizon Robotics); Shiliang Zhang (Peking University)*</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>39</span> Informative Sample-Aware Proxy for Deep Metric Learning</div><br>
<div id=program-paper-author>Aoyu Li (Tokyo Institute of Technology)*; Ikuro Sato (Tokyo Institute of Technology / Denso IT Laboratory); Kohta Ishikawa (Denso IT Laboratory, Inc.); Rei Kawakami (Tokyo Institute of Technology); Rio Yokota (Tokyo Institute of Technology)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>83</span> Federated Knowledge Transfer for Heterogeneous Visual Models</div><br>
<div id=program-paper-author>Wenzhe Li (Tsinghua University)*; Zirui Zhu (Tsinghua University); Tianchi Huang (Tsinghua University); Lifeng Sun (Tsinghua University)</div>
</div>
</div>
<div id=program-session>
<div id=program-time>
<a id=program name=2022-12-14T13:00:00+09:00>13:00
&#150;
14:00
</a>
</div>
<div id=program-session-name>
<a href=/keynote/#keynote1>Keynote 1: Machine Learning for Creative Workflow</a>
</div>
</div>
<div id=program-session>
<div id=program-time>
<a id=program name=2022-12-14T14:00:00+09:00>14:00
&#150;
14:30
</a>
</div>
<div id=program-session-name>
Demo Spotlight
</div>
</div>
<div id=program-presentatin-list>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=demo>100</span> A Music Loop Sequencer with User-adaptive Music Loop Selection</div><br>
<div id=program-paper-author>Yuki Iwamoto (Nihon University)*; Tetsuro Kitahara (Nihon University)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=demo>105</span> Action Detection System based on Pose Information</div><br>
<div id=program-paper-author>Ryo Kawai (NEC Corporation)*; Noboru Yoshida (NEC Corporation); Jianquan Liu (NEC Corporation)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=demo>106</span> DeepHair: a DeepFake-based Hairstyle Preview System</div><br>
<div id=program-paper-author>Yu-Hsuan Lo (Taipei National University of the Arts); Shih-Wei Sun (Taipei National University of the Arts)*</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=demo>107</span> Emotional Talking Faces: Making Videos More Expressive and Realistic</div><br>
<div id=program-paper-author>Sahil Goyal (IIT Roorkee)*; Shagun Uppal (IIIT-Delhi); Sarthak Bhagat (IIIT-Delhi); Dhroov Goel (IIITD); Sakshat Mali (Indraprastha Institute of Information Technology, Delhi); Yi Yu (NII); Yifang Yin (A*STAR); Rajiv Ratn Shah (IIIT Delhi)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=demo>109</span> FoodLog Athl: Multimedia Food Recording Platform for Dietary Guidance and Food Monitoring</div><br>
<div id=program-paper-author>Kei Nakamoto (The University of Tokyo)*; Kohei Kumazawa (The University of Tokyo ); Hiroaki KARASAWA (Hongo Software Development); Sosuke Amano (foo.log Inc.); Yoko Yamakata (University of Tokyo, Japan); Kiyoharu Aizawa (The University of Tokyo)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=demo>110</span> Rubber material retrieval system using electron microscope images for rubber material development</div><br>
<div id=program-paper-author>Rintaro Yanagi (Hokkaido University)*; Ren Togo (Hokkaido University); Takahiro Ogawa (Hokkaido University); Miki Haseyama (Hokkaido University)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=demo>104</span> JamSketch Deep α: A CNN-based Improvisation System in Accordance with User's Melodic Outline Drawing</div><br>
<div id=program-paper-author>Tetsuro Kitahara (Nihon University)*; Akio Yonamine (Nihon University)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=demo>108</span> GSTH266enc: A GStreamer plugin for VVC encoder</div><br>
<div id=program-paper-author>Saurabh Puri (InterDigital Inc.)*; Advaiit Rajjvaed (InterDigital Inc.); Gurdeep Bhullar (InterDigital Inc.); Gaelle Martin-Cocher (InterDigital Inc.)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=demo>101</span> Intelligent Video Surveillance Platform Based On FFmpeg And Yolov5</div><br>
<div id=program-paper-author>Chuanxu Jiang (HoHai university); Qian Huang (Hohai University)*; Yiming Wang (HoHai university); Yuhan Dai (Hohai University); Yanfang Wang (Hohai University)</div>
</div>
</div>
<div id=program-session>
<div id=program-time>
<a id=program name=2022-12-14T14:30:00+09:00>14:30
&#150;
15:45
</a>
</div>
<div id=program-session-name>
Poster+Demo
</div>
</div>
<div id=program-presentatin-list>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=demo>100</span> A Music Loop Sequencer with User-adaptive Music Loop Selection</div><br>
<div id=program-paper-author>Yuki Iwamoto (Nihon University)*; Tetsuro Kitahara (Nihon University)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=demo>105</span> Action Detection System based on Pose Information</div><br>
<div id=program-paper-author>Ryo Kawai (NEC Corporation)*; Noboru Yoshida (NEC Corporation); Jianquan Liu (NEC Corporation)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=demo>106</span> DeepHair: a DeepFake-based Hairstyle Preview System</div><br>
<div id=program-paper-author>Yu-Hsuan Lo (Taipei National University of the Arts); Shih-Wei Sun (Taipei National University of the Arts)*</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=demo>107</span> Emotional Talking Faces: Making Videos More Expressive and Realistic</div><br>
<div id=program-paper-author>Sahil Goyal (IIT Roorkee)*; Shagun Uppal (IIIT-Delhi); Sarthak Bhagat (IIIT-Delhi); Dhroov Goel (IIITD); Sakshat Mali (Indraprastha Institute of Information Technology, Delhi); Yi Yu (NII); Yifang Yin (A*STAR); Rajiv Ratn Shah (IIIT Delhi)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=demo>109</span> FoodLog Athl: Multimedia Food Recording Platform for Dietary Guidance and Food Monitoring</div><br>
<div id=program-paper-author>Kei Nakamoto (The University of Tokyo)*; Kohei Kumazawa (The University of Tokyo ); Hiroaki KARASAWA (Hongo Software Development); Sosuke Amano (foo.log Inc.); Yoko Yamakata (University of Tokyo, Japan); Kiyoharu Aizawa (The University of Tokyo)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=demo>110</span> Rubber material retrieval system using electron microscope images for rubber material development</div><br>
<div id=program-paper-author>Rintaro Yanagi (Hokkaido University)*; Ren Togo (Hokkaido University); Takahiro Ogawa (Hokkaido University); Miki Haseyama (Hokkaido University)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=demo>104</span> JamSketch Deep α: A CNN-based Improvisation System in Accordance with User's Melodic Outline Drawing</div><br>
<div id=program-paper-author>Tetsuro Kitahara (Nihon University)*; Akio Yonamine (Nihon University)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=demo>108</span> GSTH266enc: A GStreamer plugin for VVC encoder</div><br>
<div id=program-paper-author>Saurabh Puri (InterDigital Inc.)*; Advaiit Rajjvaed (InterDigital Inc.); Gurdeep Bhullar (InterDigital Inc.); Gaelle Martin-Cocher (InterDigital Inc.)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=demo>101</span> Intelligent Video Surveillance Platform Based On FFmpeg And Yolov5</div><br>
<div id=program-paper-author>Chuanxu Jiang (HoHai university); Qian Huang (Hohai University)*; Yiming Wang (HoHai university); Yuhan Dai (Hohai University); Yanfang Wang (Hohai University)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>89</span> TFM a Dataset for Detection and Recognition of Masked Faces in the Wild</div><br>
<div id=program-paper-author>Gibran Benitez-Garcia (The University of Electro-Communications)*; Miguel Jimenez-Martinez (INSTITUTO POLITECNICO NACIONAL); Jesus Olivares-Mercado (INSTITUTO POLITECNICO NACIONAL); Hiroki Takahashi (the University of Electro-Communications)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>93</span> Deep Image and Kernel Prior Learning for Blind Super-Resolution</div><br>
<div id=program-paper-author>Kazuhiro Yamawaki (Yamaguchi University); Xian-Hua Han (Yamaguchi University)*</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>42</span> Asymmetric Label Propagation for Video Object Segmentation</div><br>
<div id=program-paper-author>Zhen Chen (Peking University); Ming Yang (Horizon Robotics); Shiliang Zhang (Peking University)*</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>39</span> Informative Sample-Aware Proxy for Deep Metric Learning</div><br>
<div id=program-paper-author>Aoyu Li (Tokyo Institute of Technology)*; Ikuro Sato (Tokyo Institute of Technology / Denso IT Laboratory); Kohta Ishikawa (Denso IT Laboratory, Inc.); Rei Kawakami (Tokyo Institute of Technology); Rio Yokota (Tokyo Institute of Technology)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>83</span> Federated Knowledge Transfer for Heterogeneous Visual Models</div><br>
<div id=program-paper-author>Wenzhe Li (Tsinghua University)*; Zirui Zhu (Tsinghua University); Tianchi Huang (Tsinghua University); Lifeng Sun (Tsinghua University)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>1</span> An End-to-End Scene Text Detector with Dynamic Attention</div><br>
<div id=program-paper-author>Jingyu Lin (厦门大学); Yan Yan (Xiamen University); Hanzi Wang (Xiamen University)*</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>50</span> Self-Attentive CLIP Hashing for Unsupervised Cross-Modal Retrieval</div><br>
<div id=program-paper-author>Heng Yu (Nanjing University of Science and Technology); Shuyan Ding (Nanjing University of Science and Technology)*; Lunbo Li ( Nanjing University of Science and Technology); Jiiexin Wu (Nanjing university of Science and Technology )</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>66</span> Affective Embedding Framework with Semantic Representations from Tweets for Zero-shot Visual Sentiment Prediction</div><br>
<div id=program-paper-author>Yingrui Ye (Hokkaido University)*; Yuya Moroto (Hokkaido University); Keisuke Maeda (Hokkaido University); Takahiro Ogawa (Hokkaido University); Miki Haseyama (Hokkaido University)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>16</span> SPEAKER VGG CCT: Cross-corpus Speech Emotion Recognition with Speaker Embedding and Vision</div><br>
<div id=program-paper-author>Alessandro Arezzo (University of Florence, Italy); Stefano Berretti (University of Florence, Italy)*</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>86</span> On the Robustness of 3D Object Detectors</div><br>
<div id=program-paper-author>Fatima A Albreiki (MBZUAI ); Sultan Abughazal (MBZUAI)*; Jean Lahoud (MBZUAI); Rao Muhammad Anwer (MBZUAI/AALTO); Hisham Cholakkal (MBZUAI); Fahad Shahbaz Khan (MBZUAI)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>6</span> Robust Learning with Adversarial Perturbations and Label Noise: A Two-Pronged Defense Approach</div><br>
<div id=program-paper-author>Peng-Fei Zhang (University of Queensland)*; Zi Helen Huang (University of Queensland); Xin Luo (Shandong University); Pengfei Zhao (Shandong University)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>70</span> Enhancing the Robustness of Deep Learning Based Fingerprinting to Improve Deepfake Attribution</div><br>
<div id=program-paper-author>Chieh-Yin Liao (廖婕吟)*; Chen-hsiu Huang (National Taiwan University); Jun-Cheng Chen (Academia Sinica); Ja-Ling Wu (NTU)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>65</span> Disentangled Image Attribute Editing in Latent Space via Mask-based Retention Loss</div><br>
<div id=program-paper-author>Shunya Ohaga (Hokkaido University)*; Ren Togo (Hokkaido University); Takahiro Ogawa (Hokkaido University); Miki Haseyama (Hokkaido University)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>36</span> ObjectMix: Data Augmentation by Copy-Pasting Objects in Videos for Action Recognition</div><br>
<div id=program-paper-author>Jun Kimata (Nagoya Institute of Technology); Tmoya Nitta (Nagoya Insitute of Technology); Toru Tamaki (Nagoya Institute of Technology)*</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>20</span> CMR3D: Contextualized Multi-Stage Refinement for 3D Object Detection</div><br>
<div id=program-paper-author>Dhanalaxmi Gaddam (Mohammed Bin Zayed University of Artificial Intelligence)*; Jean Lahoud (MBZUAI); Fahad Shahbaz Khan (MBZUAI); Rao Muhammad Anwer (MBZUAI/AALTO); Hisham Cholakkal (MBZUAI)</div>
</div>
</div>
<div id=program-session>
<div id=program-time>
<a id=program name=2022-12-14T16:00:00+09:00>16:00
&#150;
17:00
</a>
</div>
<div id=program-session-name>
Oral 1-2 Text, Speech, and Vision
</div>
</div>
<div id=program-presentatin-list>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>66</span> Affective Embedding Framework with Semantic Representations from Tweets for Zero-shot Visual Sentiment Prediction</div><br>
<div id=program-paper-author>Yingrui Ye (Hokkaido University)*; Yuya Moroto (Hokkaido University); Keisuke Maeda (Hokkaido University); Takahiro Ogawa (Hokkaido University); Miki Haseyama (Hokkaido University)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>16</span> SPEAKER VGG CCT: Cross-corpus Speech Emotion Recognition with Speaker Embedding and Vision</div><br>
<div id=program-paper-author>Alessandro Arezzo (University of Florence, Italy); Stefano Berretti (University of Florence, Italy)*</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>50</span> Self-Attentive CLIP Hashing for Unsupervised Cross-Modal Retrieval</div><br>
<div id=program-paper-author>Heng Yu (Nanjing University of Science and Technology); Shuyan Ding (Nanjing University of Science and Technology)*; Lunbo Li ( Nanjing University of Science and Technology); Jiiexin Wu (Nanjing university of Science and Technology )</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>1</span> An End-to-End Scene Text Detector with Dynamic Attention</div><br>
<div id=program-paper-author>Jingyu Lin (厦门大学); Yan Yan (Xiamen University); Hanzi Wang (Xiamen University)*</div>
</div>
</div>
</div>
<div id=program-day>
<div id=program-display-date>December 15</div>
<div id=program-session>
<div id=program-time>
<a id=program name=2022-12-15T10:00:00+09:00>10:00
&#150;
11:30
</a>
</div>
<div id=program-session-name>
Oral 2-1 Video Compression, Broadcasting, and Analysis
</div>
</div>
<div id=program-presentatin-list>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>11</span> Human-Avatar Interaction in Metaverse: Framework for Full-body Interaction</div><br>
<div id=program-paper-author>Kit Yung Lam (Hong Kong University of Science and Technology)*; Ahmad ALHILAL (The Hong Kong University of Science and Technology); Liang Yang (Hong Kong University of Science and Technology); Lik Hang Lee (The University of Oulu); Gareth Tyson (Queen Mary University of London); Pan HUI (The Hong Kong University of Science and Technology)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>49</span> Parallel Queries for Human-Object Interaction Detection</div><br>
<div id=program-paper-author>Junwen Chen (The University of Electro-Communications)*; Keiji Yanai (Univ. Electro-Comm., Tokyo)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>95</span> Sequential Frame-Interpolation and DCT-based Video Compression Framework</div><br>
<div id=program-paper-author>Yeganeh Jalalpour (Portland State University)*; Wu-chi Feng (Portland State University); Feng Liu (Portland State University)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>25</span> 360BroadView: Viewer Management for Viewport Prediction in 360-Degree Video Live Broadcast</div><br>
<div id=program-paper-author>Qian Zhou (University of Illinois at Urbana-Champaign)*; Zhe Yang (University of Illinois at Urbana-Champaign); Hongpeng Guo (University of Illinois at Urbana Champaign); Beitong Tian (University of Illinois at Urbana Champaign); Klara Nahrstedt (University of Illinois at Urbana-Champaign)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>72</span> Two-Layer Learning-based P-Frame Coding with Super-Resolution and Content-Adaptive Conditional ANF</div><br>
<div id=program-paper-author>David Alexandre (National Yang Ming Chiao Tung University)*; Hsueh-Ming Hang (National Yang Ming Chiao Tung University); Wen-Hsiao Peng (National Yang Ming Chiao Tung University)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>74</span> Learned Bi-Directional Motion Prediction for Video Compression</div><br>
<div id=program-paper-author>Yunhui Shi (Beijing University of Technology)*; Shaopei An (Beijing University of Technology); Jin Wang (Beijing University of Technology); Baocai Yin (Beijing University of Technology)</div>
</div>
</div>
<div id=program-session>
<div id=program-time>
<a id=program name=2022-12-15T13:00:00+09:00>13:00
&#150;
14:00
</a>
</div>
<div id=program-session-name>
<a href=/keynote/#keynote2>Keynote 2: Connecting the Dots: Digital Humanities and Historical Big Data Research for Japanese Culture</a>
</div>
</div>
<div id=program-session>
<div id=program-time>
<a id=program name=2022-12-15T14:00:00+09:00>14:00
&#150;
15:00
</a>
</div>
<div id=program-session-name>
Short Spotlight
</div>
</div>
<div id=program-presentatin-list>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=short>9</span> A Multimodal Sensor Fusion Framework Robust to Missing Modalities for Person Recognition</div><br>
<div id=program-paper-author>Vijay John (RIKEN)*; Yasutomo Kawanishi (RIKEN)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=short>24</span> A Reality Check of Positioning in Multiuser Mobile Augmented Reality: Measurement and Analysis</div><br>
<div id=program-paper-author>Na Wang (George Mason University)*; Haoliang Wang (Adobe Research); Stefano Petrangeli (Adobe); Viswanathan (Vishy) Swaminathan (Adobe); Fei Li (George Mason University); Songqing Chen (George Mason University)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=short>34</span> SLGAN: Style- and Latent-guided Generative Adversarial Network for Desirable Makeup Transfer and Removal</div><br>
<div id=program-paper-author>Daichi Horita (The University of Tokyo)*; Kiyoharu Aizawa (The University of Tokyo)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=short>64</span> Popularity-aware Graph Social Recommendation for Fully Non-Interaction Users</div><br>
<div id=program-paper-author>Nozomu Onodera (Hokkaido University)*; Keisuke Maeda (Hokkaido University); Takahiro Ogawa (Hokkaido University); Miki Haseyama (Hokkaido University)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=short>90</span> Graph Neural Network Based Living Comfort Prediction Using Real Estate Floor Plan Images</div><br>
<div id=program-paper-author>Ryota Kitabayashi (The University of Tokyo)*; Taro Narahara (njit); Toshihiko Yamasaki (The University of Tokyo)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=short>28</span> Multimodal Fusion with Cross-Modal Attention for Action Recognition in Still Images</div><br>
<div id=program-paper-author>Jia-Hua Tsai (Department of Computer Science and Information Engineering, National Cheng-Kung University); Wei-Ta Chu (National Cheng Kung University)*</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=short>45</span> Zero-shot Font Style Transfer with a Differentiable Renderer</div><br>
<div id=program-paper-author>Kota Izumi (The University of Electro-Communications); Keiji Yanai (Univ. Electro-Comm., Tokyo)*</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=short>98</span> Wearable Camera Based Food Logging System</div><br>
<div id=program-paper-author>Kenshiro Sato (The University of Tokyo)*; Yoko Yamakata (University of Tokyo, Japan); Sosuke Amano (foo.log Inc.); Kiyoharu Aizawa (The University of Tokyo)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=short>48</span> Wider or Deeper Neural Network Architecture for Acoustic Scene Classification with Mismatched Recording Devices</div><br>
<div id=program-paper-author>LAM PHAM (Austrian Institute of Technology)*; Khoa Tran (Da Nang University); Dat Ngo (University of Essex); Hieu Tang (FPT University); Son Phan (Earable AI); Alexander Schindler (Austrian Institute of Technology)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=short>59</span> Towards High Performance One-Stage Human Pose Estimation</div><br>
<div id=program-paper-author>Ling Li (Nanjing University of Science and Technology)*; Lin Zhao (Nanjing University of Science and Technology); Linhao Xu (Nanjing University of Science and Technology); Jie Xu (Nanjing University of Science and Technology)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=short>85</span> Singing Voice Detection via Similarity-based Semi-supervised Learning Method</div><br>
<div id=program-paper-author>Xi Chen (Fudan University)*</div>
</div>
</div>
<div id=program-session>
<div id=program-time>
<a id=program name=2022-12-15T15:15:00+09:00>15:15
&#150;
17:00
</a>
</div>
<div id=program-session-name>
Poster+Demo
</div>
</div>
<div id=program-presentatin-list>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=demo>100</span> A Music Loop Sequencer with User-adaptive Music Loop Selection</div><br>
<div id=program-paper-author>Yuki Iwamoto (Nihon University)*; Tetsuro Kitahara (Nihon University)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=demo>105</span> Action Detection System based on Pose Information</div><br>
<div id=program-paper-author>Ryo Kawai (NEC Corporation)*; Noboru Yoshida (NEC Corporation); Jianquan Liu (NEC Corporation)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=demo>106</span> DeepHair: a DeepFake-based Hairstyle Preview System</div><br>
<div id=program-paper-author>Yu-Hsuan Lo (Taipei National University of the Arts); Shih-Wei Sun (Taipei National University of the Arts)*</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=demo>107</span> Emotional Talking Faces: Making Videos More Expressive and Realistic</div><br>
<div id=program-paper-author>Sahil Goyal (IIT Roorkee)*; Shagun Uppal (IIIT-Delhi); Sarthak Bhagat (IIIT-Delhi); Dhroov Goel (IIITD); Sakshat Mali (Indraprastha Institute of Information Technology, Delhi); Yi Yu (NII); Yifang Yin (A*STAR); Rajiv Ratn Shah (IIIT Delhi)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=demo>109</span> FoodLog Athl: Multimedia Food Recording Platform for Dietary Guidance and Food Monitoring</div><br>
<div id=program-paper-author>Kei Nakamoto (The University of Tokyo)*; Kohei Kumazawa (The University of Tokyo ); Hiroaki KARASAWA (Hongo Software Development); Sosuke Amano (foo.log Inc.); Yoko Yamakata (University of Tokyo, Japan); Kiyoharu Aizawa (The University of Tokyo)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=demo>110</span> Rubber material retrieval system using electron microscope images for rubber material development</div><br>
<div id=program-paper-author>Rintaro Yanagi (Hokkaido University)*; Ren Togo (Hokkaido University); Takahiro Ogawa (Hokkaido University); Miki Haseyama (Hokkaido University)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=demo>104</span> JamSketch Deep α: A CNN-based Improvisation System in Accordance with User's Melodic Outline Drawing</div><br>
<div id=program-paper-author>Tetsuro Kitahara (Nihon University)*; Akio Yonamine (Nihon University)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=demo>108</span> GSTH266enc: A GStreamer plugin for VVC encoder</div><br>
<div id=program-paper-author>Saurabh Puri (InterDigital Inc.)*; Advaiit Rajjvaed (InterDigital Inc.); Gurdeep Bhullar (InterDigital Inc.); Gaelle Martin-Cocher (InterDigital Inc.)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=demo>101</span> Intelligent Video Surveillance Platform Based On FFmpeg And Yolov5</div><br>
<div id=program-paper-author>Chuanxu Jiang (HoHai university); Qian Huang (Hohai University)*; Yiming Wang (HoHai university); Yuhan Dai (Hohai University); Yanfang Wang (Hohai University)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=short>9</span> A Multimodal Sensor Fusion Framework Robust to Missing Modalities for Person Recognition</div><br>
<div id=program-paper-author>Vijay John (RIKEN)*; Yasutomo Kawanishi (RIKEN)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=short>24</span> A Reality Check of Positioning in Multiuser Mobile Augmented Reality: Measurement and Analysis</div><br>
<div id=program-paper-author>Na Wang (George Mason University)*; Haoliang Wang (Adobe Research); Stefano Petrangeli (Adobe); Viswanathan (Vishy) Swaminathan (Adobe); Fei Li (George Mason University); Songqing Chen (George Mason University)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=short>34</span> SLGAN: Style- and Latent-guided Generative Adversarial Network for Desirable Makeup Transfer and Removal</div><br>
<div id=program-paper-author>Daichi Horita (The University of Tokyo)*; Kiyoharu Aizawa (The University of Tokyo)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=short>64</span> Popularity-aware Graph Social Recommendation for Fully Non-Interaction Users</div><br>
<div id=program-paper-author>Nozomu Onodera (Hokkaido University)*; Keisuke Maeda (Hokkaido University); Takahiro Ogawa (Hokkaido University); Miki Haseyama (Hokkaido University)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=short>90</span> Graph Neural Network Based Living Comfort Prediction Using Real Estate Floor Plan Images</div><br>
<div id=program-paper-author>Ryota Kitabayashi (The University of Tokyo)*; Taro Narahara (njit); Toshihiko Yamasaki (The University of Tokyo)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=short>28</span> Multimodal Fusion with Cross-Modal Attention for Action Recognition in Still Images</div><br>
<div id=program-paper-author>Jia-Hua Tsai (Department of Computer Science and Information Engineering, National Cheng-Kung University); Wei-Ta Chu (National Cheng Kung University)*</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=short>45</span> Zero-shot Font Style Transfer with a Differentiable Renderer</div><br>
<div id=program-paper-author>Kota Izumi (The University of Electro-Communications); Keiji Yanai (Univ. Electro-Comm., Tokyo)*</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=short>98</span> Wearable Camera Based Food Logging System</div><br>
<div id=program-paper-author>Kenshiro Sato (The University of Tokyo)*; Yoko Yamakata (University of Tokyo, Japan); Sosuke Amano (foo.log Inc.); Kiyoharu Aizawa (The University of Tokyo)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=short>48</span> Wider or Deeper Neural Network Architecture for Acoustic Scene Classification with Mismatched Recording Devices</div><br>
<div id=program-paper-author>LAM PHAM (Austrian Institute of Technology)*; Khoa Tran (Da Nang University); Dat Ngo (University of Essex); Hieu Tang (FPT University); Son Phan (Earable AI); Alexander Schindler (Austrian Institute of Technology)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=short>59</span> Towards High Performance One-Stage Human Pose Estimation</div><br>
<div id=program-paper-author>Ling Li (Nanjing University of Science and Technology)*; Lin Zhao (Nanjing University of Science and Technology); Linhao Xu (Nanjing University of Science and Technology); Jie Xu (Nanjing University of Science and Technology)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=short>85</span> Singing Voice Detection via Similarity-based Semi-supervised Learning Method</div><br>
<div id=program-paper-author>Xi Chen (Fudan University)*</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>11</span> Human-Avatar Interaction in Metaverse: Framework for Full-body Interaction</div><br>
<div id=program-paper-author>Kit Yung Lam (Hong Kong University of Science and Technology)*; Ahmad ALHILAL (The Hong Kong University of Science and Technology); Liang Yang (Hong Kong University of Science and Technology); Lik Hang Lee (The University of Oulu); Gareth Tyson (Queen Mary University of London); Pan HUI (The Hong Kong University of Science and Technology)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>49</span> Parallel Queries for Human-Object Interaction Detection</div><br>
<div id=program-paper-author>Junwen Chen (The University of Electro-Communications)*; Keiji Yanai (Univ. Electro-Comm., Tokyo)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>95</span> Sequential Frame-Interpolation and DCT-based Video Compression Framework</div><br>
<div id=program-paper-author>Yeganeh Jalalpour (Portland State University)*; Wu-chi Feng (Portland State University); Feng Liu (Portland State University)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>25</span> 360BroadView: Viewer Management for Viewport Prediction in 360-Degree Video Live Broadcast</div><br>
<div id=program-paper-author>Qian Zhou (University of Illinois at Urbana-Champaign)*; Zhe Yang (University of Illinois at Urbana-Champaign); Hongpeng Guo (University of Illinois at Urbana Champaign); Beitong Tian (University of Illinois at Urbana Champaign); Klara Nahrstedt (University of Illinois at Urbana-Champaign)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>72</span> Two-Layer Learning-based P-Frame Coding with Super-Resolution and Content-Adaptive Conditional ANF</div><br>
<div id=program-paper-author>David Alexandre (National Yang Ming Chiao Tung University)*; Hsueh-Ming Hang (National Yang Ming Chiao Tung University); Wen-Hsiao Peng (National Yang Ming Chiao Tung University)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>74</span> Learned Bi-Directional Motion Prediction for Video Compression</div><br>
<div id=program-paper-author>Yunhui Shi (Beijing University of Technology)*; Shaopei An (Beijing University of Technology); Jin Wang (Beijing University of Technology); Baocai Yin (Beijing University of Technology)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>55</span> Deep Enhancement-Object Features Fusion for Low-light Object Detection</div><br>
<div id=program-paper-author>Wan Teng Lim (Multimedia University); Kelvin Ang (Multimedia University); Yuen Peng Loh (Multimedia University)*</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>7</span> Image Compression for Machines Using Boundary-Enhanced Saliency</div><br>
<div id=program-paper-author>Yuanyuan Xu (Hohai University)*; Haolun Lan (Hohai University)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>30</span> Deep Weighted Guided Upsampling Network for Depth of Field Image Upsampling</div><br>
<div id=program-paper-author>Lanling Zeng (Jiangsu University)*; Lianxiong Wu (Jiangsu University); Yang Yang ( Jiangsu University); Xiang-Jun Shen (Jiangsu University); Yongzhao Zhan (UJS)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>57</span> Multispectral Image Denoising Via Structural Tensor Sparsity Promoting Model</div><br>
<div id=program-paper-author>longlu huang (Beijing University Of Technology); Na Qi (Beijing University of Technology)*; Qing Zhu (Beijing University of Technology)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>53</span> Multi-scale Channel Transformer Network for Single Image Deraining</div><br>
<div id=program-paper-author>Yuto Namba (Yamaguchi University)*; Xian-Hua Han (Yamaguchi University)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>67</span> Remote sensing image colorization based on Joint Stream Deep Convolutional Generative Adversarial Networks</div><br>
<div id=program-paper-author>Jingyu J Wang (Ocean University of China); Jie Nie (Ocean University of China)*; Hao Chen (Ocean University of China); Huaxin Xie (Ocean University of China); chengyu zheng (Ocean University of China); Min Ye (Ocean university of China); Zhiqiang Wei (Ocean University of China)</div>
</div>
</div>
</div>
<div id=program-day>
<div id=program-display-date>December 16</div>
<div id=program-session>
<div id=program-time>
<a id=program name=2022-12-16T10:00:00+09:00>10:00
&#150;
11:30
</a>
</div>
<div id=program-session-name>
Oral 3-1 Low-level Vision and Image Processing
</div>
</div>
<div id=program-presentatin-list>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>55</span> Deep Enhancement-Object Features Fusion for Low-light Object Detection</div><br>
<div id=program-paper-author>Wan Teng Lim (Multimedia University); Kelvin Ang (Multimedia University); Yuen Peng Loh (Multimedia University)*</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>7</span> Image Compression for Machines Using Boundary-Enhanced Saliency</div><br>
<div id=program-paper-author>Yuanyuan Xu (Hohai University)*; Haolun Lan (Hohai University)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>30</span> Deep Weighted Guided Upsampling Network for Depth of Field Image Upsampling</div><br>
<div id=program-paper-author>Lanling Zeng (Jiangsu University)*; Lianxiong Wu (Jiangsu University); Yang Yang ( Jiangsu University); Xiang-Jun Shen (Jiangsu University); Yongzhao Zhan (UJS)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>57</span> Multispectral Image Denoising Via Structural Tensor Sparsity Promoting Model</div><br>
<div id=program-paper-author>longlu huang (Beijing University Of Technology); Na Qi (Beijing University of Technology)*; Qing Zhu (Beijing University of Technology)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>53</span> Multi-scale Channel Transformer Network for Single Image Deraining</div><br>
<div id=program-paper-author>Yuto Namba (Yamaguchi University)*; Xian-Hua Han (Yamaguchi University)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>67</span> Remote sensing image colorization based on Joint Stream Deep Convolutional Generative Adversarial Networks</div><br>
<div id=program-paper-author>Jingyu J Wang (Ocean University of China); Jie Nie (Ocean University of China)*; Hao Chen (Ocean University of China); Huaxin Xie (Ocean University of China); chengyu zheng (Ocean University of China); Min Ye (Ocean university of China); Zhiqiang Wei (Ocean University of China)</div>
</div>
</div>
<div id=program-session>
<div id=program-time>
<a id=program name=2022-12-16T13:00:00+09:00>13:00
&#150;
14:30
</a>
</div>
<div id=program-session-name>
Oral 3-2 Robustness, Data Augmentation and Disentangling
</div>
</div>
<div id=program-presentatin-list>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>86</span> On the Robustness of 3D Object Detectors</div><br>
<div id=program-paper-author>Fatima A Albreiki (MBZUAI ); Sultan Abughazal (MBZUAI)*; Jean Lahoud (MBZUAI); Rao Muhammad Anwer (MBZUAI/AALTO); Hisham Cholakkal (MBZUAI); Fahad Shahbaz Khan (MBZUAI)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>6</span> Robust Learning with Adversarial Perturbations and Label Noise: A Two-Pronged Defense Approach</div><br>
<div id=program-paper-author>Peng-Fei Zhang (University of Queensland)*; Zi Helen Huang (University of Queensland); Xin Luo (Shandong University); Pengfei Zhao (Shandong University)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>70</span> Enhancing the Robustness of Deep Learning Based Fingerprinting to Improve Deepfake Attribution</div><br>
<div id=program-paper-author>Chieh-Yin Liao (廖婕吟)*; Chen-hsiu Huang (National Taiwan University); Jun-Cheng Chen (Academia Sinica); Ja-Ling Wu (NTU)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>65</span> Disentangled Image Attribute Editing in Latent Space via Mask-based Retention Loss</div><br>
<div id=program-paper-author>Shunya Ohaga (Hokkaido University)*; Ren Togo (Hokkaido University); Takahiro Ogawa (Hokkaido University); Miki Haseyama (Hokkaido University)</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>36</span> ObjectMix: Data Augmentation by Copy-Pasting Objects in Videos for Action Recognition</div><br>
<div id=program-paper-author>Jun Kimata (Nagoya Institute of Technology); Tmoya Nitta (Nagoya Insitute of Technology); Toru Tamaki (Nagoya Institute of Technology)*</div>
</div>
<div id=program-presentation>
<div id=program-paper-title><span id=program-paper-id class=oral>20</span> CMR3D: Contextualized Multi-Stage Refinement for 3D Object Detection</div><br>
<div id=program-paper-author>Dhanalaxmi Gaddam (Mohammed Bin Zayed University of Artificial Intelligence)*; Jean Lahoud (MBZUAI); Fahad Shahbaz Khan (MBZUAI); Rao Muhammad Anwer (MBZUAI/AALTO); Hisham Cholakkal (MBZUAI)</div>
</div>
</div>
<div id=program-session>
<div id=program-time>
<a id=program name=2022-12-16T14:30:00+09:00>14:30
&#150;
14:45
</a>
</div>
<div id=program-session-name>
Closing
</div>
</div>
</div>
</div>
<br>
</div>
</div>
</div>
</div>
<footer id=footer>
<div class=container>
<div class="col-md-4 col-sm-6">
<h4>About us</h4>
<p>ACM Multimedia Asia 2022 at Tokyo, Japan <br> 13 - 16 December, 2022.　<br>Any questions? question@mmasia2022.org </p>
<hr class="hidden-md hidden-lg hidden-sm">
</div>
<div class="col-md-4 col-sm-6">
<h4>Recent posts</h4>
<div class=blog-entries>
<div class="item same-height-row clearfix">
<div class="image same-height-always">
<a href=https://www.mmasia2022.org/blog/2022/10/24/registration-site-is-now-online/>
<img src=/img/registration.jpeg class=img-responsive alt="Registration site is now online">
</a>
</div>
<div class="name same-height-always">
<h5><a href=https://www.mmasia2022.org/blog/2022/10/24/registration-site-is-now-online/>Registration site is now online</a></h5>
</div>
</div>
<div class="item same-height-row clearfix">
<div class="image same-height-always">
<a href=https://www.mmasia2022.org/blog/2022/10/24/program-released/>
<img src=/img/program.jpeg class=img-responsive alt="Program is now out">
</a>
</div>
<div class="name same-height-always">
<h5><a href=https://www.mmasia2022.org/blog/2022/10/24/program-released/>Program is now out</a></h5>
</div>
</div>
<div class="item same-height-row clearfix">
<div class="image same-height-always">
<a href=https://www.mmasia2022.org/blog/2022/10/01/info-of-student-travel_grants-released/>
<img src=/img/travel_grants.jpg class=img-responsive alt="We are accepting applications for student travel grants">
</a>
</div>
<div class="name same-height-always">
<h5><a href=https://www.mmasia2022.org/blog/2022/10/01/info-of-student-travel_grants-released/>We are accepting applications for student travel grants</a></h5>
</div>
</div>
</div>
<hr class="hidden-md hidden-lg">
</div>
</div>
</footer>
<div id=copyright>
<div class=container>
<div class=col-md-12>
<p class=pull-left>Copyright (c) 2021, ACM Multimedia Asia 2022; all rights reserved.</p>
<p class=pull-right>
Template by <a href=https://bootstrapious.com/p/universal-business-e-commerce-template>Bootstrapious</a>.
Ported to Hugo by <a href=https://github.com/devcows/hugo-universal-theme>DevCows</a>.
</p>
</div>
</div>
</div>
</div>
<script src=//code.jquery.com/jquery-3.1.1.min.js integrity="sha256-hVVnYaiADRTO2PzUGmuLJr8BLUSjGIZsDYGmIJLv2b8=" crossorigin=anonymous></script>
<script src=//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js integrity=sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa crossorigin=anonymous></script>
<script src=//cdnjs.cloudflare.com/ajax/libs/jquery-cookie/1.4.1/jquery.cookie.min.js></script>
<script src=//cdnjs.cloudflare.com/ajax/libs/waypoints/4.0.1/jquery.waypoints.min.js></script>
<script src=//cdnjs.cloudflare.com/ajax/libs/Counter-Up/1.0/jquery.counterup.min.js></script>
<script src=//cdnjs.cloudflare.com/ajax/libs/jquery-parallax/1.1.3/jquery-parallax.js></script>
<script src=/js/front.js></script>
<script src=/js/owl.carousel.min.js></script>
</body>
</html>