<!doctype html><html lang=en-us>
<head>
<meta charset=utf-8>
<meta name=robots content="all,follow">
<meta name=googlebot content="index,follow,snippet,archive">
<meta name=viewport content="width=device-width,initial-scale=1">
<title>Call for Workhop Papers</title>
<meta name=author content="DevCows">
<meta name=keywords content="announcement">
<meta name=description content="ACM Multimedia Asia 2022">
<meta name=generator content="Hugo 0.89.4">
<link href="//fonts.googleapis.com/css?family=Roboto:400,100,100italic,300,300italic,500,700,800" rel=stylesheet type=text/css>
<link rel=stylesheet href=//use.fontawesome.com/releases/v5.11.2/css/all.css>
<link rel=stylesheet href=//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css integrity=sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u crossorigin=anonymous>
<link href=/css/animate.css rel=stylesheet>
<link href=/css/style.marsala.css rel=stylesheet id=theme-stylesheet>
<link href=/css/custom.css rel=stylesheet><!--[if lt IE 9]><script src=https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js></script>
<script src=https://oss.maxcdn.com/respond/1.4.2/respond.min.js></script><![endif]-->
<link rel="shortcut icon" href=/img/favicon.ico type=image/x-icon>
<link rel=apple-touch-icon href=/img/apple-touch-icon.png>
<link href=/css/owl.carousel.css rel=stylesheet>
<link href=/css/owl.theme.css rel=stylesheet>
<link rel=alternate href=https://www.mmasia2022.org/index.xml type=application/rss+xml title="ACM Multimedia Asia 2022">
<meta name=twitter:card content="summary">
<meta name=twitter:site content="@GoHugoIO">
<meta name=twitter:title content="Call for Workhop Papers">
<meta name=twitter:description content="ACM Multimedia Asia 2022">
<link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css>
</head>
<body>
<div id=all>
<header class=navbar-affixed-top data-spy=affix data-offset-top=62>
<div class="navbar navbar-default yamm" role=navigation id=navbar>
<div class=container>
<div class=navbar-header>
<a class="navbar-brand home" href=/>
<img src=/img/logo-acmmmasia2022.png alt="Call for Workhop Papers logo" class="hidden-xs hidden-sm">
<img src=/img/logo-acmmmasia2022.png alt="Call for Workhop Papers logo" class="visible-xs visible-sm">
<span class=sr-only>Call for Workhop Papers - go to homepage</span>
</a>
<div class=navbar-buttons>
<button type=button class="navbar-toggle btn-template-main" data-toggle=collapse data-target=#navigation>
<span class=sr-only>Toggle Navigation</span>
<i class="fas fa-align-justify"></i>
</button>
</div>
</div>
<div class="navbar-collapse collapse" id=navigation>
<ul class="nav navbar-nav navbar-right">
<li class=dropdown>
<a href=/>Home</a>
</li>
<li class=dropdown>
<a href=# class=dropdown-toggle data-toggle=dropdown role=button aria-haspopup=true aria-expanded=false>Calls & Dates <span class=caret></span></a>
<ul class=dropdown-menu>
<li><a href=/important_dates/>Important Dates</a></li>
<li><a href=/call_for_workshop_proposals/>Call for Workshop Proposals</a></li>
<li><a href=/call_for_regular_papers/>Call for Regular Papers</a></li>
<li><a href=/call_for_short_papers/>Call for Short Papers</a></li>
<li><a href=/call_for_demo_papers/>Call for Demo Papers</a></li>
<li><a href=/call_for_tutorials/>Call for Tutorials</a></li>
<li><a href=/call_for_workshop_papers/>Call for Workshop Papers</a></li>
</ul>
</li>
<li class=dropdown>
<a href>Program</a>
</li>
<li class=dropdown>
<a href=# class=dropdown-toggle data-toggle=dropdown role=button aria-haspopup=true aria-expanded=false>Attend <span class=caret></span></a>
<ul class=dropdown-menu>
<li><a href=/venue>Venue</a></li>
<li><a href=/student-travel-grants>Student Travel Grants</a></li>
</ul>
</li>
<li class=dropdown>
<a href=/sponsors/>Sponsors</a>
</li>
<li class=dropdown>
<a href=/organizers/>Organizers</a>
</li>
</ul>
</div>
<div class="collapse clearfix" id=search>
<form class=navbar-form role=search>
<div class=input-group>
<input type=text class=form-control placeholder=Search>
<span class=input-group-btn>
<button type=submit class="btn btn-template-main"><i class="fas fa-search"></i></button>
</span>
</div>
</form>
</div>
</div>
</div>
</header>
<div id=heading-breadcrumbs>
<div class=container>
<div class=row>
<div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
<h1>Call for Workhop Papers</h1>
</div>
</div>
</div>
</div>
<div id=content>
<div class=container role=main>
<div class=row>
<div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1 lead">
<h2 id=list-of-workshops>List of workshops:</h2>
<ul>
<li><a href=#multimedia-understanding-with-pre-trained-models>Workshop on Multimedia Understanding with Pre-trained Models</a></li>
<li><a href=#the-7th-international-workshop-on-affective-social-multimedia-computing>The 7th International Workshop on Affective Social Multimedia Computing</a></li>
</ul>
<br>
<br>
<h3 id=multimedia-understanding-with-pre-trained-models>Multimedia Understanding with Pre-trained Models</h3>
<p><a href=http://staff.ustc.edu.cn/~zhwg/MMAsia_2022_workshop/index.html>http://staff.ustc.edu.cn/~zhwg/MMAsia_2022_workshop/index.html</a></p>
<h4 id=overview>Overview</h4>
<p>Multi-modal understanding plays a crucial role in enabling the machine to perceive the physical world with multiple sensor cues as humans. Recently, large-scale pre-trained models (PTMs) has become a research hotspot in the field of artificial intelligence. Existing techniques follow the self-supervised learning paradigm achieve great success on the uni-modal scenes, such as computer vision (CV) and natural language process (NLP). The recent advances in large-scale pre-trained models inspire the researchers to explore more and deeper pre-training techniques for the multi-modal understanding problem. In this workshop, we aim to bring together researchers from the field of multimedia to discuss recent research and future directions on pre-trained models with self-supervised learning for multimedia understanding.</p>
<p>In recent years, we have witnessed the great success of pre-trained models (PTM) in natural language processing (NLP), such as GPT3, BERT, Roberta, DEBERTA, etc. It motivates the researchers in the multimedia community to leverage the idea of PTM to address multi-modal tasks. The scope of this workshop is focused on pre-trained models with self-supervised learning for multimedia understanding. The potential topics include architecture design for multi-modal PTM, pre-text task design for self-supervised learning, multi-modal data modeling, efficiency enhancing for PTM, interpretability of PTM, etc.</p>
<h4 id=call-for-papers>Call for Papers</h4>
<p>Multi-modal understanding plays a crucial role in enabling the machine to perceive the physical world with multiple sensor cues as humans. Recently, large-scale pre-trained models (PTMs) has become a research hotspot in the field of artificial intelligence. Existing techniques follow the self-supervised learning paradigm achieve great success on the uni-modal scenes, such as computer vision (CV) and natural language process (NLP). The recent advances in large-scale pre-trained models inspire the researchers to explore more and deeper pre-training techniques for the multi-modal understanding problem. In this workshop, we aim to bring together researchers from the field of multimedia to discuss recent research and future directions on pre-trained models with self-supervised learning for multimedia understanding.</p>
<ul>
<li>Unified PTM strategies for multi-modal understanding</li>
<li>PTM for cross-modal matching and retrieval</li>
<li>PTM for audio-visual understanding</li>
<li>PTM for video captioning</li>
<li>PTM for sign language translation</li>
<li>Leveraging off-the-shelf PTM for multi-modal understanding</li>
<li>Interpretability in self-supervised PTM</li>
</ul>
<h4 id=paper-submission-guideline>Paper Submission Guideline</h4>
<p>To be announced.</p>
<br>
<br>
<h3 id=the-7th-international-workshop-on-affective-social-multimedia-computing>The 7th International Workshop on Affective Social Multimedia Computing</h3>
<p><a href=http://asmmc22.ubtrobot.com/#>http://asmmc22.ubtrobot.com/#</a></p>
<h4 id=call-for-papers-1>Call for Papers</h4>
<p>Affective social multimedia computing is an emergent research topic for both affective computing and multimedia research communities. Social multimedia is fundamentally changing how we communicate, interact, and collaborate with other people in our daily lives. Comparing with well-organized broadcast news and professionally made videos such as commercials, TV shows, and movies, social multimedia media computing imposes great challenges to research communities. Social multimedia contains much affective information. Effective extraction of affective information from social multimedia can greatly help social multimedia computing (e.g., processing, index, retrieval, and understanding). Although much progress have been made in traditional multimedia research on multimedia content analysis, indexing, and retrieval based on subjective concepts such as emotion, aesthetics, and preference, affective social multimedia computing is a new research area. The affective social multimedia computing aims to proceed affective information from social multi-media. For massive and heterogeneous social media data, the research requires multidisciplinary understanding of content and perceptual cues from social multimedia. From the multimedia perspective, the research relies on the theoretical and technological findings in affective computing, machine learning, pattern recognition, signal/multimedia processing, computer vision, speech processing, behavior and social psychology. Affective analysis of social multimedia is attracting growing attention from industry and businesses that provide social networking sites, content-sharing services, distribute and host the media. This workshop focuses on the analysis of affective signals in interaction (multimodal analyses enabling artificial agents in Human-Machine Interaction, social Interaction with artificial agents) and social multimedia (e.g., twitter, wechat, weibo, youtube, facebook, etc).</p>
<p>The 1st, 2nd, 3rd, 4th, 5th , 6th ASMMC workshop have been successfully held in Xi’an, China on September 21, 2015, Seattle, USA on July 15, 2016, Stockholm, Sweden on August 25, 2017, Seoul, Korea on October 26, 2018, and Cambridge， UK on July 2, 2019, Virtual conference (Montreal, Canada) on October 11, 2021 respectively. We take the 7th ASMMC to ACM Multimedia Asia 2022 come back again to Affective Computing & Intelligent Interaction for investigating affective computing technology to become available and accessible to education, health, transport, cities, home and entertainments.</p>
<h4 id=workshop-scope>Workshop Scope</h4>
<p>The workshop will address, but is not limited to, the following topics:</p>
<ul>
<li>Affective human-machine interaction or human-human interaction</li>
<li>Affective/Emotional content analysis of images, videos, music, metadata (text, symbols, etc.)</li>
<li>Affective indexing, ranking, and retrieval on big social media data</li>
<li>Affective computing in social multimedia by multimodal integration (face expression, gesture, posture, speech, text/language)</li>
<li>Emotional implicit tagging and interactive systems</li>
<li>User interests and behavior modeling in social multimedia</li>
<li>Video and image summarization based on affect</li>
<li>Affective analysis of social media and harvesting the affective response of crowd</li>
<li>Affective generation in social multimedia, expressive text-to-speech and expressive language translation</li>
<li>Zero/One/Few-shot learning for emotion recognition</li>
<li>Multimodal Analyses enabling Artificial Agents in Human-Machine Interaction</li>
<li>Social Interaction with Artificial Agents</li>
<li>Applications of affective social multimedia computing</li>
</ul>
<h4 id=paper-submission-guideline-1>Paper Submission Guideline</h4>
<p>To be announced.</p>
</div>
</div>
</div>
</div>
<footer id=footer>
<div class=container>
<div class="col-md-4 col-sm-6">
<h4>About us</h4>
<p>ACM Multimedia Asia 2022 at Tokyo, Japan <br> 13 - 16 December, 2022.　<br>Any questions? question@mmasia2022.org </p>
<hr class="hidden-md hidden-lg hidden-sm">
</div>
<div class="col-md-4 col-sm-6">
<h4>Recent posts</h4>
<div class=blog-entries>
<div class="item same-height-row clearfix">
<div class="image same-height-always">
<a href=https://www.mmasia2022.org/blog/2022/10/01/info-of-student-travel_grants-released/>
<img src=/img/travel_grants.jpg class=img-responsive alt="We are accepting applications for student travel grants">
</a>
</div>
<div class="name same-height-always">
<h5><a href=https://www.mmasia2022.org/blog/2022/10/01/info-of-student-travel_grants-released/>We are accepting applications for student travel grants</a></h5>
</div>
</div>
<div class="item same-height-row clearfix">
<div class="image same-height-always">
<a href=https://www.mmasia2022.org/blog/2022/08/26/deadline-extended-3rd/>
<img src=/img/extention.jpg class=img-responsive alt="Deadline Extended: Tutorial Proposals">
</a>
</div>
<div class="name same-height-always">
<h5><a href=https://www.mmasia2022.org/blog/2022/08/26/deadline-extended-3rd/>Deadline Extended: Tutorial Proposals</a></h5>
</div>
</div>
<div class="item same-height-row clearfix">
<div class="image same-height-always">
<a href=https://www.mmasia2022.org/blog/2022/08/19/demo-paper-deadline-extended/>
<img src=/img/extention.jpg class=img-responsive alt="Deadline Extended: Demo Papers">
</a>
</div>
<div class="name same-height-always">
<h5><a href=https://www.mmasia2022.org/blog/2022/08/19/demo-paper-deadline-extended/>Deadline Extended: Demo Papers</a></h5>
</div>
</div>
</div>
<hr class="hidden-md hidden-lg">
</div>
</div>
</footer>
<div id=copyright>
<div class=container>
<div class=col-md-12>
<p class=pull-left>Copyright (c) 2021, ACM Multimedia Asia 2022; all rights reserved.</p>
<p class=pull-right>
Template by <a href=https://bootstrapious.com/p/universal-business-e-commerce-template>Bootstrapious</a>.
Ported to Hugo by <a href=https://github.com/devcows/hugo-universal-theme>DevCows</a>.
</p>
</div>
</div>
</div>
</div>
<script src=//code.jquery.com/jquery-3.1.1.min.js integrity="sha256-hVVnYaiADRTO2PzUGmuLJr8BLUSjGIZsDYGmIJLv2b8=" crossorigin=anonymous></script>
<script src=//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js integrity=sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa crossorigin=anonymous></script>
<script src=//cdnjs.cloudflare.com/ajax/libs/jquery-cookie/1.4.1/jquery.cookie.min.js></script>
<script src=//cdnjs.cloudflare.com/ajax/libs/waypoints/4.0.1/jquery.waypoints.min.js></script>
<script src=//cdnjs.cloudflare.com/ajax/libs/Counter-Up/1.0/jquery.counterup.min.js></script>
<script src=//cdnjs.cloudflare.com/ajax/libs/jquery-parallax/1.1.3/jquery-parallax.js></script>
<script src=/js/front.js></script>
<script src=/js/owl.carousel.min.js></script>
</body>
</html>